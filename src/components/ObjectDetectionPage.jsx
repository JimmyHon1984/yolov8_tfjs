import React, { useState, useRef, useEffect } from "react";
import { detect, detectVideo } from "../utils/detect";
import { Webcam } from "../utils/webcam";
import "../style/ObjectDetectionPage.css";

const ObjectDetectionPage = ({ model, trainedModels, onReturnHome }) => {
  const [streaming, setStreaming] = useState(null);
  const [selectedModel, setSelectedModel] = useState("é€šç”¨ç‰©ä»¶æ¨¡å‹ (é è¨­)");
  const [isDetecting, setIsDetecting] = useState(false);
  const [metrics, setMetrics] = useState({ inferenceTime: 0, fps: 0 });
  const [isDragging, setIsDragging] = useState(false);
  const [panelWidth, setPanelWidth] = useState(360);
  const [isFullscreen, setIsFullscreen] = useState(false);
  const [imageUrl, setImageUrl] = useState(null); // æ–°å¢ï¼šç›´æ¥è¿½è¸ªåœ–ç‰‡URL
  
  // åƒè€ƒ
  const imageRef = useRef(null);
  const videoRef = useRef(null);
  const cameraRef = useRef(null);
  const canvasRef = useRef(null);
  const inputImageRef = useRef(null);
  const inputVideoRef = useRef(null);
  const resizerRef = useRef(null);
  const displayContainerRef = useRef(null);
  const contentRef = useRef(null);
  
  // ç¶²è·¯æ”å½±æ©Ÿè™•ç†
  const webcam = new Webcam();
  
  // é—œé–‰åœ–ç‰‡
  const closeImage = () => {
    if (imageUrl) {
      URL.revokeObjectURL(imageUrl);
    }
    setImageUrl(null);
    setStreaming(null);
    if (inputImageRef.current) inputImageRef.current.value = "";
    
    // æ¸…é™¤ç•«å¸ƒ
    if (canvasRef.current) {
      const ctx = canvasRef.current.getContext("2d");
      ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
    }
  };
  
  // é—œé–‰å½±ç‰‡
  const closeVideo = () => {
    if (!videoRef.current) return;
    
    const url = videoRef.current.src;
    if (url && url !== "") {
      videoRef.current.src = "";
      URL.revokeObjectURL(url);
    }
    setStreaming(null);
    if (inputVideoRef.current) inputVideoRef.current.value = "";
    if (videoRef.current) videoRef.current.style.display = "none";
    
    // æ¸…é™¤ç•«å¸ƒ
    if (canvasRef.current) {
      const ctx = canvasRef.current.getContext("2d");
      ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
    }
  };
  
  // æ›´æ–°æ•ˆèƒ½æŒ‡æ¨™
  const updateMetrics = (inferenceTime, fps = 0) => {
    console.log("Metrics updated:", inferenceTime, fps);
    setMetrics({ inferenceTime, fps });
  };
  
  // åŸ·è¡Œåµæ¸¬
  const handleDetect = () => {
    if (!imageRef.current || !canvasRef.current) {
      console.error("Image or canvas reference not available");
      return;
    }
    
    console.log("Starting detection...");
    setIsDetecting(true);
    
    if (streaming === "image") {
      detect(imageRef.current, model, canvasRef.current, () => {
        console.log("Detection completed");
        setIsDetecting(false);
      }, updateMetrics);
    }
  };

  // æ‹–æ”¾è™•ç†å‡½æ•¸
  const handleDragOver = (e) => {
    e.preventDefault();
    setIsDragging(true);
  };

  const handleDragLeave = () => {
    setIsDragging(false);
  };

  const handleDrop = (e) => {
    e.preventDefault();
    setIsDragging(false);
    console.log("File dropped");

    if (e.dataTransfer.files.length > 0) {
      const file = e.dataTransfer.files[0];
      console.log("File type:", file.type);
      
      const type = file.type.startsWith('image/') ? 'image' : 
                  file.type.startsWith('video/') ? 'video' : null;

      if (type === 'image') {
        console.log("Processing image file");
        if (streaming === "video") closeVideo();
        if (streaming === "camera" && cameraRef.current) {
          webcam.close(cameraRef.current);
          cameraRef.current.style.display = "none";
        }

        handleImageFile(file);
      } else if (type === 'video' && videoRef.current) {
        console.log("Processing video file");
        if (streaming === "image") closeImage();
        if (streaming === "camera" && cameraRef.current) {
          webcam.close(cameraRef.current);
          cameraRef.current.style.display = "none";
        }

        const url = URL.createObjectURL(file);
        videoRef.current.src = url;
        videoRef.current.addEventListener("ended", () => closeVideo());
        videoRef.current.style.display = "block";
        setStreaming("video");
      } else {
        console.error("Unsupported file type or references not available");
      }
    }
  };

  // æ–°å¢ï¼šè™•ç†åœ–ç‰‡æ–‡ä»¶
  const handleImageFile = (file) => {
    try {
      // æ¸…é™¤ä»»ä½•ä»¥å‰çš„åœ–ç‰‡URL
      if (imageUrl) {
        URL.revokeObjectURL(imageUrl);
      }
      
      // å‰µå»ºæ–°çš„URLä¸¦ä¿å­˜
      const newUrl = URL.createObjectURL(file);
      console.log("New image URL created:", newUrl);
      setImageUrl(newUrl);
      setStreaming("image");
    } catch (error) {
      console.error("Error handling image file:", error);
    }
  };

  // å…¨è¢å¹•åŠŸèƒ½
  const toggleFullscreen = () => {
    if (!displayContainerRef.current) return;
    
    if (!isFullscreen) {
      if (displayContainerRef.current.requestFullscreen) {
        displayContainerRef.current.requestFullscreen();
      } else if (displayContainerRef.current.mozRequestFullScreen) { // Firefox
        displayContainerRef.current.mozRequestFullScreen();
      } else if (displayContainerRef.current.webkitRequestFullscreen) { // Chrome, Safari
        displayContainerRef.current.webkitRequestFullscreen();
      } else if (displayContainerRef.current.msRequestFullscreen) { // IE/Edge
        displayContainerRef.current.msRequestFullscreen();
      }
    } else {
      if (document.exitFullscreen) {
        document.exitFullscreen();
      } else if (document.mozCancelFullScreen) {
        document.mozCancelFullScreen();
      } else if (document.webkitExitFullscreen) {
        document.webkitExitFullscreen();
      } else if (document.msExitFullscreen) {
        document.msExitFullscreen();
      }
    }
  };

  // ç›£è½å…¨è¢å¹•è®ŠåŒ–
  useEffect(() => {
    const handleFullscreenChange = () => {
      setIsFullscreen(
        document.fullscreenElement ||
        document.mozFullScreenElement ||
        document.webkitFullscreenElement ||
        document.msFullscreenElement
      );
    };
    
    document.addEventListener('fullscreenchange', handleFullscreenChange);
    document.addEventListener('mozfullscreenchange', handleFullscreenChange);
    document.addEventListener('webkitfullscreenchange', handleFullscreenChange);
    document.addEventListener('MSFullscreenChange', handleFullscreenChange);
    
    return () => {
      document.removeEventListener('fullscreenchange', handleFullscreenChange);
      document.removeEventListener('mozfullscreenchange', handleFullscreenChange);
      document.removeEventListener('webkitfullscreenchange', handleFullscreenChange);
      document.removeEventListener('MSFullscreenChange', handleFullscreenChange);
    };
  }, []);
  
  // åˆ†å‰²ç·šèª¿æ•´åŠŸèƒ½
  useEffect(() => {
    if (!resizerRef.current) return;
    
    const resizer = resizerRef.current;
    let isResizing = false;
    let startX = 0;
    let startWidth = 0;
    
    const startResize = (e) => {
      isResizing = true;
      startX = e.clientX;
      startWidth = panelWidth;
      document.body.classList.add('resizing');
      resizer.classList.add('resizing');
    };
    
    const doResize = (e) => {
      if (!isResizing) return;
      
      const newWidth = startWidth + (e.clientX - startX);
      // è¨­ç½®æœ€å°å’Œæœ€å¤§å€¼
      if (newWidth >= 250 && newWidth <= 500) {
        setPanelWidth(newWidth);
        resizer.style.left = `${newWidth}px`;
      }
    };
    
    const endResize = () => {
      isResizing = false;
      document.body.classList.remove('resizing');
      resizer.classList.remove('resizing');
    };
    
    resizer.addEventListener('mousedown', startResize);
    document.addEventListener('mousemove', doResize);
    document.addEventListener('mouseup', endResize);
    
    return () => {
      resizer.removeEventListener('mousedown', startResize);
      document.removeEventListener('mousemove', doResize);
      document.removeEventListener('mouseup', endResize);
    };
  }, [panelWidth]);
  
  // éµç›¤å¿«æ·éµ
  useEffect(() => {
    const handleKeyPress = (e) => {
      // ESC éµé—œé–‰ç•¶å‰é¡¯ç¤ºçš„å…§å®¹
      if (e.key === 'Escape') {
        if (streaming === "image") closeImage();
        else if (streaming === "video") closeVideo();
        else if (streaming === "camera" && cameraRef.current) {
          webcam.close(cameraRef.current);
          cameraRef.current.style.display = "none";
          setStreaming(null);
          
          if (canvasRef.current) {
            const ctx = canvasRef.current.getContext("2d");
            ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
          }
        }
      }
      
      // 1, 2, 3 éµå¯ä»¥å¿«é€Ÿé¸æ“‡è¼¸å…¥æº
      if (e.key === '1' && inputImageRef.current) inputImageRef.current.click();
      if (e.key === '2' && inputVideoRef.current) inputVideoRef.current.click();
      if (e.key === '3' && streaming !== "camera" && cameraRef.current) {
        if (streaming === "image") closeImage();
        if (streaming === "video") closeVideo();
        
        webcam.open(cameraRef.current);
        cameraRef.current.style.display = "block";
        setStreaming("camera");
      }
      
      // Space éµå¯ä»¥åœ¨åœ–ç‰‡æ¨¡å¼ä¸‹å•Ÿå‹•è­˜åˆ¥
      if (e.key === ' ' && streaming === "image" && !isDetecting) {
        handleDetect();
      }
      
      // F éµå¯ä»¥åˆ‡æ›å…¨è¢å¹•
      if (e.key === 'f' || e.key === 'F') {
        toggleFullscreen();
      }
    };
    
    window.addEventListener('keydown', handleKeyPress);
    return () => {
      window.removeEventListener('keydown', handleKeyPress);
    };
  }, [streaming, isDetecting]);
  
  // ç¢ºä¿åœ¨çµ„ä»¶å¸è¼‰æ™‚é‡‹æ”¾è³‡æº
  useEffect(() => {
    return () => {
      if (streaming === "camera" && cameraRef.current) {
        webcam.close(cameraRef.current);
      }
      if (imageUrl) {
        URL.revokeObjectURL(imageUrl);
      }
    };
  }, [streaming, imageUrl]);
  
  // å°å‡ºéšæ®µè³‡è¨Šç”¨æ–¼é™¤éŒ¯
  useEffect(() => {
    console.log("Current streaming state:", streaming);
    console.log("Current image URL:", imageUrl);
  }, [streaming, imageUrl]);
  
  // åœ–ç‰‡è¼‰å…¥æ•ˆæœ
  useEffect(() => {
    if (streaming === "image" && imageUrl && imageRef.current) {
      console.log("Setting image src:", imageUrl);
      
      // ç¢ºä¿åœ–ç‰‡å…ƒç´ å¯è¦‹
      imageRef.current.style.display = "block";
      imageRef.current.src = imageUrl;
      
      // åˆå§‹åŒ–ç•«å¸ƒ
      if (canvasRef.current) {
        canvasRef.current.style.display = "block";
      }
    }
  }, [streaming, imageUrl]);
  
  // ç•¶åœ–ç‰‡åŠ è¼‰å®Œæˆå¾Œè‡ªå‹•é€²è¡Œæª¢æ¸¬
  const handleImageLoad = () => {
    console.log("Image loaded successfully:", imageRef.current?.src);
    // In handleImageLoad in ObjectDetectionPage.jsx
    console.log("Image dimensions:", imageRef.current.width, imageRef.current.height);
    console.log("Canvas dimensions:", canvasRef.current.width, canvasRef.current.height);
    
    if (imageRef.current && canvasRef.current) {
    // Get the natural (original) dimensions of the image
    const naturalWidth = imageRef.current.naturalWidth;
    const naturalHeight = imageRef.current.naturalHeight;
      
    // Calculate how the image will be displayed (without scaling up)
    const containerWidth = contentRef.current.clientWidth;
    const containerHeight = contentRef.current.clientHeight;
      
    // Calculate the display scale (capped at 1.0 to prevent upscaling)
    const displayScale = Math.min(
      containerWidth * 0.9 / naturalWidth,
      containerHeight * 0.9 / naturalHeight,
      1.0
    );
    
    // Calculate actual displayed dimensions
    const displayWidth = Math.round(naturalWidth * displayScale);
    const displayHeight = Math.round(naturalHeight * displayScale);
    
    console.log(`Original dimensions: ${naturalWidth}x${naturalHeight}`);
    console.log(`Display dimensions: ${displayWidth}x${displayHeight}`);
    
    // Set image to exact dimensions
    imageRef.current.style.width = `${displayWidth}px`;
    imageRef.current.style.height = `${displayHeight}px`;
    imageRef.current.style.maxWidth = 'none';
    imageRef.current.style.maxHeight = 'none';
    
    // Set canvas to match exactly the image dimensions - this is critical
        canvasRef.current.width = displayWidth;
        canvasRef.current.height = displayHeight;
        
    // Position canvas exactly over the image
        const imageRect = imageRef.current.getBoundingClientRect();
        const contentRect = contentRef.current.getBoundingClientRect();
        
        canvasRef.current.style.position = "absolute";
        canvasRef.current.style.left = `${imageRect.left - contentRect.left}px`;
        canvasRef.current.style.top = `${imageRect.top - contentRect.top}px`;
        canvasRef.current.style.width = `${displayWidth}px`;
        canvasRef.current.style.height = `${displayHeight}px`;
        
    const detectWithCorrectRatios = () => {
    // Calculate the display scale factor relative to the original image
    const displayScaleX = displayWidth / naturalWidth;
    const displayScaleY = displayHeight / naturalHeight;
    
    detect(
      imageRef.current, 
      model, 
      canvasRef.current, 
      () => {
        console.log("Detection completed with correct scaling");
        setIsDetecting(false);
      }, 
      updateMetrics,
      displayScaleX  // Pass this as the displayRatio parameter
    );
  };
    
    detectWithCorrectRatios();
  }
};
  
  return (
    <div className="detection-container">
      <header className="detection-header">
        <h1>ç‰©ä»¶è­˜åˆ¥æ¸¬è©¦</h1>
        <div className="header-actions">
          <div className="shortcut-hint">æŒ‰ F1 é¡¯ç¤ºå¿«æ·éµå¹«åŠ©</div>
          <button className="return-button" onClick={onReturnHome}>è¿”å›ä¸»é </button>
        </div>
      </header>
      
      <div className="detection-main">
        <div className="detection-panel" style={{ width: `${panelWidth}px` }}>
          <div className="panel-header">
            <h2>é¸æ“‡è¼¸å…¥ä¾†æº</h2>
          </div>
          
          <div className="input-methods">
            <div className={`input-method ${streaming === 'image' ? 'active' : ''}`}>
              <div className="method-icon">ğŸ–¼ï¸</div>
              <div className="method-content">
                <h3>åœ–ç‰‡è­˜åˆ¥ <span className="shortcut-badge">1</span></h3>
                <p>ä¸Šå‚³åœ–ç‰‡é€²è¡Œç‰©ä»¶è­˜åˆ¥</p>
                <input
                  type="file"
                  accept="image/*"
                  style={{ display: "none" }}
                  onChange={(e) => {
                    console.log("Image input changed");
                    if (e.target.files.length > 0) {
                      const file = e.target.files[0];
                      console.log("Processing selected image file:", file.name);
                      
                      // å¦‚æœå…¶ä»–ä¸²æµæ­£åœ¨é€²è¡Œï¼Œå…ˆé—œé–‰
                      if (streaming === "video") closeVideo();
                      if (streaming === "camera" && cameraRef.current) {
                        webcam.close(cameraRef.current);
                        cameraRef.current.style.display = "none";
                      }
                      
                      handleImageFile(file);
                    }
                  }}
                  ref={inputImageRef}
                />
                <button 
                  className="method-button tooltip" 
                  onClick={() => {
                    if (streaming !== "image" && inputImageRef.current) {
                      console.log("Triggering image selection");
                      inputImageRef.current.click();
                    } else {
                      console.log("Closing image");
                      closeImage();
                    }
                  }}
                >
                  {streaming === "image" ? "å–æ¶ˆ" : "é¸æ“‡åœ–ç‰‡"}
                  <span className="tooltip-text">é¸æ“‡åœ–ç‰‡æˆ–ç›´æ¥æ‹–æ”¾åˆ°å³å´å€åŸŸ</span>
                </button>
              </div>
            </div>
            
            <div className={`input-method ${streaming === 'video' ? 'active' : ''}`}>
              <div className="method-icon">ğŸ¬</div>
              <div className="method-content">
                <h3>å½±ç‰‡è­˜åˆ¥ <span className="shortcut-badge">2</span></h3>
                <p>ä¸Šå‚³å½±ç‰‡é€²è¡Œç‰©ä»¶è­˜åˆ¥</p>
                <input
                  type="file"
                  accept="video/*"
                  style={{ display: "none" }}
                  onChange={(e) => {
                    console.log("Video input changed");
                    if (e.target.files.length > 0 && videoRef.current) {
                      // å¦‚æœå…¶ä»–ä¸²æµæ­£åœ¨é€²è¡Œï¼Œå…ˆé—œé–‰
                      if (streaming === "image") closeImage();
                      if (streaming === "camera" && cameraRef.current) {
                        webcam.close(cameraRef.current);
                        cameraRef.current.style.display = "none";
                      }
                      
                      const url = URL.createObjectURL(e.target.files[0]);
                      videoRef.current.src = url;
                      videoRef.current.addEventListener("ended", () => closeVideo());
                      videoRef.current.style.display = "block";
                      setStreaming("video");
                    }
                  }}
                  ref={inputVideoRef}
                />
                <button 
                  className="method-button tooltip" 
                  onClick={() => {
                    if (streaming !== "video" && inputVideoRef.current) {
                      inputVideoRef.current.click();
                    } else {
                      closeVideo();
                    }
                  }}
                >
                  {streaming === "video" ? "å–æ¶ˆ" : "é¸æ“‡å½±ç‰‡"}
                  <span className="tooltip-text">é¸æ“‡å½±ç‰‡æˆ–ç›´æ¥æ‹–æ”¾åˆ°å³å´å€åŸŸ</span>
                </button>
              </div>
            </div>
            
            <div className={`input-method ${streaming === 'camera' ? 'active' : ''}`}>
              <div className="method-icon">ğŸ“¹</div>
              <div className="method-content">
                <h3>æ”å½±æ©Ÿè­˜åˆ¥ <span className="shortcut-badge">3</span></h3>
                <p>ä½¿ç”¨ç¶²è·¯æ”å½±æ©Ÿé€²è¡Œå³æ™‚ç‰©ä»¶è­˜åˆ¥</p>
                <button 
                  className="method-button tooltip"
                  onClick={() => {
                    if (streaming !== "camera" && cameraRef.current) {
                      // å¦‚æœå…¶ä»–ä¸²æµæ­£åœ¨é€²è¡Œï¼Œå…ˆé—œé–‰
                      if (streaming === "image") closeImage();
                      if (streaming === "video") closeVideo();
                      
                      webcam.open(cameraRef.current);
                      cameraRef.current.style.display = "block";
                      setStreaming("camera");
                    } else if (cameraRef.current) {
                      webcam.close(cameraRef.current);
                      cameraRef.current.style.display = "none";
                      setStreaming(null);
                      
                      // æ¸…é™¤ç•«å¸ƒ
                      if (canvasRef.current) {
                        const ctx = canvasRef.current.getContext("2d");
                        ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
                      }
                    }
                  }}
                >
                  {streaming === "camera" ? "é—œé–‰æ”å½±æ©Ÿ" : "é–‹å•Ÿæ”å½±æ©Ÿ"}
                  <span className="tooltip-text">é–‹å•Ÿæˆ–é—œé–‰ç¶²è·¯æ”å½±æ©Ÿ</span>
                </button>
              </div>
            </div>
          </div>
          
          {streaming && (
            <div className="detection-controls">
              <div className="model-selector">
                <label htmlFor="model-selector">é¸æ“‡è­˜åˆ¥æ¨¡å‹</label>
                <select 
                  id="model-selector" 
                  value={selectedModel}
                  onChange={(e) => setSelectedModel(e.target.value)}
                >
                  <option value="é€šç”¨ç‰©ä»¶æ¨¡å‹ (é è¨­)">é€šç”¨ç‰©ä»¶æ¨¡å‹ (é è¨­)</option>
                  {trainedModels && trainedModels.map((m, index) => (
                    <option key={index} value={m.name}>{m.name}</option>
                  ))}
                </select>
              </div>
              
              {streaming === "image" && (
                <button 
                  className="detect-button tooltip" 
                  onClick={handleDetect}
                  disabled={isDetecting}
                >
                  {isDetecting ? "è­˜åˆ¥ä¸­..." : "é–‹å§‹è­˜åˆ¥"}
                  <span className="tooltip-text">æŒ‰ç©ºæ ¼éµä¹Ÿå¯ä»¥é–‹å§‹è­˜åˆ¥</span>
                </button>
              )}
            </div>
          )}
          
          {streaming && (
            <div className="metrics-panel">
              <div className="metric-item">
                <div className="metric-label">æ¨è«–æ™‚é–“</div>
                <div className="metric-value">{metrics.inferenceTime.toFixed(2)} ms</div>
              </div>
              {(streaming === "video" || streaming === "camera") && (
                <div className="metric-item">
                  <div className="metric-label">æ¯ç§’å¹€æ•¸</div>
                  <div className="metric-value">{metrics.fps.toFixed(1)} FPS</div>
                </div>
              )}
            </div>
          )}
          
          <div className="keyboard-shortcuts">
            <h3>éµç›¤å¿«æ·éµ:</h3>
            <div className="shortcut-list">
              <div className="key-combo">1</div>
              <div className="key-description">ä¸Šå‚³åœ–ç‰‡</div>
              
              <div className="key-combo">2</div>
              <div className="key-description">ä¸Šå‚³å½±ç‰‡</div>
              
              <div className="key-combo">3</div>
              <div className="key-description">é–‹å•Ÿ/é—œé–‰æ”å½±æ©Ÿ</div>
              
              <div className="key-combo">Space</div>
              <div className="key-description">åœ–ç‰‡æ¨¡å¼ä¸‹é–‹å§‹è­˜åˆ¥</div>
              
              <div className="key-combo">F</div>
              <div className="key-description">åˆ‡æ›å…¨è¢å¹•</div>
              
              <div className="key-combo">Esc</div>
              <div className="key-description">é—œé–‰ç•¶å‰é¡¯ç¤ºå…§å®¹</div>
            </div>
          </div>
        </div>
        
        <div className="resizer" ref={resizerRef}></div>
        
        <div className="detection-display">
          <div 
            ref={displayContainerRef}
            className={`display-container ${isDragging ? 'dragging' : ''} ${isFullscreen ? 'fullscreen' : ''}`}
            onDragOver={handleDragOver}
            onDragLeave={handleDragLeave}
            onDrop={handleDrop}
          >
            {!streaming ? (
              <div className="placeholder">
                <div className="placeholder-icon">ğŸ”</div>
                <p>è«‹é¸æ“‡å·¦å´çš„è¼¸å…¥ä¾†æºä»¥é–‹å§‹è­˜åˆ¥</p>
                <p className="drop-hint">æˆ–ç›´æ¥æ‹–æ”¾åœ–ç‰‡/å½±ç‰‡æ–‡ä»¶åˆ°æ­¤è™•</p>
              </div>
            ) : (
              <div 
                ref={contentRef} 
                className="content"
                style={{
                  position: "relative",
                  display: "flex",
                  justifyContent: "center",
                  alignItems: "center",
                  width: "100%", 
                  height: "100%",
                  overflow: "hidden"
                }}
              >
                {streaming === "image" && (
                  <img
                    ref={imageRef}
                    src={imageUrl || "#"}
                    alt="åµæ¸¬åœ–ç‰‡"
                    onLoad={handleImageLoad}
                    style={{
                      display: imageUrl ? "block" : "none",   
                    }}
                  />
                )}
                
                <video
                  ref={videoRef}
                  autoPlay
                  muted
                  style={{ 
                    display: streaming === "video" ? "block" : "none",
                    maxWidth: "90%", 
                    maxHeight: "90%"
                  }}
                  onPlay={() => {
                    console.log("Video started playing");
                    if (videoRef.current && canvasRef.current) {
                      detectVideo(videoRef.current, model, canvasRef.current, updateMetrics);
                    }
                  }}
                />
                
                <video
                  ref={cameraRef}
                  autoPlay
                  muted
                  style={{ 
                    display: streaming === "camera" ? "block" : "none",
                    maxWidth: "90%", 
                    maxHeight: "90%"
                  }}
                  onPlay={() => {
                    console.log("Camera started streaming");
                    if (cameraRef.current && canvasRef.current) {
                      detectVideo(cameraRef.current, model, canvasRef.current, updateMetrics);
                    }
                  }}
                />
                
                <canvas 
                  ref={canvasRef} 
                  style={{
                    position: "absolute",
                    pointerEvents: "none",
                    zIndex: 10
                  }}
                />
              </div>
            )}
            
            {isDragging && (
              <div className="drop-overlay">
                <div className="drop-icon">ğŸ“¥</div>
                <div className="drop-message">é‡‹æ”¾æ–‡ä»¶ä»¥ä¸Šå‚³</div>
              </div>
            )}
            
            <button className="fullscreen-button" onClick={toggleFullscreen}>
              {isFullscreen ? 'é›¢é–‹å…¨è¢å¹•' : 'å…¨è¢å¹•é¡¯ç¤º'}
            </button>
          </div>
        </div>
      </div>
      
      {/* èª¿è©¦ä¿¡æ¯ */}
      {imageUrl && (
        <div style={{
          position: "fixed",
          bottom: "10px",
          left: "10px",
          background: "rgba(0,0,0,0.7)",
          color: "white",
          padding: "8px",
          borderRadius: "4px",
          fontSize: "12px",
          zIndex: 9999
        }}>
          å·²è¼‰å…¥åœ–ç‰‡: {imageUrl.substring(0, 30)}...
        </div>
      )}
    </div>
  );
};

export default ObjectDetectionPage;
